{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                                     # Reading the Data #\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e05263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # 导入pandas库，用pd作别名\n",
    "HOUSING_PATH = os.path.join(\"datasets\",\"housing\") # 指定下载数据到的目录 datasets/housing/\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path,\"housing.csv\")\n",
    "    return pd.read_csv(csv_path) # 返回一个包含所有数据的 pandas 数据框架对象\n",
    "housing = load_housing_data() # 返回一个包含所有数据的 pandas 数据框架对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98e199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                                     # Create a Test set #\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7eadbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分层抽样 根据收入中位数来进行分层抽样\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 将 median_income 的数据按照bins来划分，并给每个区间中的数据打上label\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],bins=[0.,1.5,3,4.5,6.,np.inf],labels=[1,2,3,4,5])\n",
    "# 现在层次已经分出来了，我们要做的就是在每一层选择一些样本出来\n",
    "# sklearn 提供了 StratifiedShuffleSplit 函数来进行分层抽样\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# n_splits 表示只分成一对 test/train 集，返回的还是一个 StratifiedShuffleSplit 对象\n",
    "split_obj = StratifiedShuffleSplit(n_splits=1,test_size=0.2, random_state=42)\n",
    "# split_obj.split(数据集X，参照列y) 将数据集按照参照列进行分层，本质上是利用了参照列的分布\n",
    "for test_index, train_index in split_obj.split(housing,housing[\"income_cat\"]):\n",
    "    # 这个循环会执行 n_splits 那么多次，这里只执行一次\n",
    "    strat_train_set = housing.loc[train_index] # loc作用于数据的label上，iloc作用于数据存储的indexs上\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "# strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set) # value_counts得到这一列的分布\n",
    "# 通过dataframe.columns来查看所有列\n",
    "strat_train_set.columns\n",
    "# 需要删除掉 income_cat 这个属性，因为这是人工加上去的\n",
    "for set_ in (strat_train_set,strat_test_set):\n",
    "    set_.drop(\"income_cat\",axis=1,inplace=True) # axis指明这是按列删除，前面的“income_cat”表示该列的标识\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836f5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                      # Prepare the Data for Machine Learning Algorithms (数据预处理)#\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439003e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先分离标签数据和参考数据\n",
    "housing = strat_train_set.drop(\"median_house_value\",axis=1) # drop 操作会拷贝，所以本身不会变化\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "housing_num = housing.drop(\"ocean_proximity\",axis=1) # 在参考数据中分离出类别数据和数值数据\n",
    "####### 先做一个自定义的 Transfromer 后面会用到 ###############\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombineAttributesAddr(BaseEstimator,TransformerMixin): # 括号里面表示继承的基类\n",
    "    def __init__(self,add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room # add_bedrooms_per_room 是一个超参\n",
    "    def fit(self,X,y = None):\n",
    "        # 实现fit方法\n",
    "        return self;\n",
    "    def transform(self,X,y = None):\n",
    "        # 实现transform方法\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room] # np.c_用于按列连接两个矩阵\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "###############################################################\n",
    "#### 4. Transformation Pipelines\n",
    "   # Pipeline的思想就是将上面所有对数据的操作连接起来\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('add_addr',CombineAttributesAddr()),\n",
    "    ('std_scaler',StandardScaler())\n",
    "])# Pipeline的参数是一个list，每个元素是一个tuple,指明名字和使用的estimator，最后一个tuple得是一个transformer\n",
    "# 然后直接调用num_pipeline的fit_transform方法传入housing的数值数据就可以一步完成上面的空值填充，属性组合，标准化等操作了\n",
    "# 但是上面的pipeline只是对于数值数据进行操作，还希望对housing数据中类别数据进行transform,\n",
    "from sklearn.compose import ColumnTransformer\n",
    "num_attr = list(housing_num) # 获取housing_num的所有列名\n",
    "cate_attr = [\"ocean_proximity\"] # 类型一致\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\",num_pipeline,num_attr),\n",
    "    (\"cate\",OneHotEncoder(),cate_attr)\n",
    "]) # ColumnTransformer的参数是一个list，每一个元素是一个tuple，tuple里面分别是名称，transformer,该transformer要transform的列名们\n",
    "\n",
    "# 最后调用一下就OK\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f8e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                                 # Select and Train a Model #\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89f189c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 1. Training and Evaluating on the Training Set\n",
    "###  首先看下线性回归的效果\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_gre = LinearRegression()\n",
    "lin_gre.fit(housing_prepared,housing_labels) # 线性回归模型的fit方法用于拟合，参数是样本和标签\n",
    "###  看看训练出来的模型的误差，使用均方根误差(实际上就是概率意义上的标准差)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_gre.predict(housing_prepared)\n",
    "housing_mse = mean_squared_error(housing_labels,housing_predictions)\n",
    "housing_rmse = np.sqrt(housing_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e754949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66787.70814784677"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b217141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 66787这样的误差相对于原始数据的120000到265000的尺度来说是0.1，有点大了\n",
    "### 这种就属于是underfitting, 我们可以换一个模型试试\n",
    "### 下面我们换一个更为强大的模型----决策树模型\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "deci_tree = DecisionTreeRegressor()\n",
    "deci_tree.fit(housing_prepared,housing_labels)\n",
    "housing_tree_predictions = deci_tree.predict(housing_prepared)\n",
    "housing_tree_mse = mean_squared_error(housing_labels,housing_tree_predictions)\n",
    "housing_tree_rmse = np.sqrt(housing_tree_mse)\n",
    "housing_tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbe5d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [73120.44097041 80056.42921501 75085.06576066 72159.55538572\n",
      " 69716.36551322 67562.50553407 76229.53737292 81835.7613273\n",
      " 68813.90660527 77779.85206916]\n",
      "Mean: 74235.94197537546\n",
      "Standard deviation: 4569.524867021512\n"
     ]
    }
   ],
   "source": [
    "### 看到这里误差为0 就明白极大可能是过拟合了，但我们还是不敢确定，所以要进行验证\n",
    "### 但是验证的话我们不能动测试集中的数据，所以我们把训练集中的数据一部分用来训练，一部分用来验证(validation)\n",
    "\n",
    "### 2. Better Evaluation Using Cross-Validation\n",
    "  ### 在交叉验证前，一般是先将训练集数据分为k个部分，这个k称为 折(fold) ，在交叉验证中, 一般需要进行k次训练和验证，\n",
    "  ### 每次从k个fold中选择一个fold作为验证集，其余的k-1个fold作为训练集，一次的训练和验证产生一个训练-验证分数(实际上就是一个误差)\n",
    "  ### 然后再选择另外一个不同的fold作为验证集，以此类推。最后得到一个长度为k的训练-验证分数向量\n",
    "  ### 交叉验证可以让我们看到所选择的模型的预测能力，还能够通过标准差来反映这种预测能力的准确性(它产生的误差范围)\n",
    "\n",
    "  ### 使用sklearn.model_selection的cross_val_score可以完成交叉验证功能\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 第一个参数是分类器，第二三个参数分别是：数据特征和标签，第四个参数是计算分数的方法，cv是折数\n",
    "scores = cross_val_score(deci_tree,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4232a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [66830.21497764 73595.46286068 67888.5957665  69274.18198153\n",
      " 66475.99624101 66144.88036095 64702.02705501 65639.32837098\n",
      " 67105.20129799 67421.10791841]\n",
      "Mean: 67507.69968307031\n",
      "Standard deviation: 2350.3018828733475\n"
     ]
    }
   ],
   "source": [
    "### 可以看到 分数的均值甚至比线性回归模型还要拉胯，为了公平一些，我们还是看看线性回归模型在交叉验证下的表现\n",
    "linea_scores = cross_val_score(lin_gre,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "linea_rmse_scores = np.sqrt(-linea_scores)\n",
    "display_scores(linea_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b67429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000.02800493825"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 看吧看吧，看来线性回归模型还是要比决策树模型要好的\n",
    "### 但是线性回归模型underfitting了不是，那我们还是再看看其他模型\n",
    "\n",
    "### 接下来采用随机森林回归模型\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared,housing_labels)\n",
    "forest_prediction = forest_reg.predict(housing_prepared)\n",
    "forest_rmse = np.sqrt(mean_squared_error(housing_labels,forest_prediction))\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91b3d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [53678.52449407 55553.74763448 52792.99273884 52058.35724143\n",
      " 49828.09373462 52787.20341053 53256.55306957 53646.69768675\n",
      " 51870.16717542 59704.61997053]\n",
      "Mean: 53517.69571562395\n",
      "Standard deviation: 2490.9885046295963\n"
     ]
    }
   ],
   "source": [
    "### 可以看到比线性回归模型好了很多了，那在验证集下(交叉验证)的表现如何呢？\n",
    "forest_scores = cross_val_score(forest_reg,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611abebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 可以看到均值已经好了很多了，但是在验证集下的结果比训练集下的结果更拉胯(得多)，说明overfitting了\n",
    "\n",
    "### 现在整理一下思路，在线性模型上由于在训练集上的结果就很拉胯说明underfitting了\n",
    "### 换了一个决策树模型，结果训练集上表现完美，但是验证集上表现比线性模型更拉胯，说明overfitting了\n",
    "### 又换了一个随机森林模型，结果训练集上表现相对于线性模型要好一些了，而验证集上的该模型又比决策树模型好了一些，但是还是由于验证集比训练集烂太多而overfitting了\n",
    "\n",
    "### 我们可以再试试其他的模型，文中提出在选择模型阶段我们一般选出2-5个表现比较好的模型就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9caa748a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'joblib' from 'sklearn.externals' (d:\\python\\lib\\site-packages\\sklearn\\externals\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17968\\3488815304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 很多时候我们应该要保存我们选择出来的模型(训练好了的)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"my_model.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## 保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# my_model_loaded = joblib.load(\"my_model.pkl\") ## 读入\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (d:\\python\\lib\\site-packages\\sklearn\\externals\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# 很多时候我们应该要保存我们选择出来的模型(训练好了的)\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(my_model, \"my_model.pkl\") ## 保存\n",
    "# my_model_loaded = joblib.load(\"my_model.pkl\") ## 读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                                     # Fine-Tune Your Model #\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "136b4ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'n_estimators': 30}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 拥有了选择好的一些模型后，我们需要对这些模型进行微调(fine-tune)\n",
    "##### 1. 一种进行微调的方法就是调整超参数，这里用到的是网格搜索(没错，就是基于笛卡尔积的那种网格)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{\"n_estimators\":[3,10,30],\"max_features\":[2,4,6,8]},\n",
    "              {\"bootstrap\":[False],\"n_estimators\":[3,10],\"max_features\":[2,3,4]}]\n",
    "# 这里 param_grid 是要作为参数传入GridSearchCV中的\n",
    "# 列表里面的每一个字典都是一组需要测试的超参: \n",
    "###### 'n_estimators'，'max_features'，'bootstrap'是超参们，它们的意义后面会介绍，这里它们的两个列表会做一个笛卡尔积的操作，即：\n",
    "######  [3,2],[3,4],[3,6]，...它们作为超参组合被用于训练以及验证\n",
    "######  第二个字典还增加了bootstrap为false的超参进去进行对比， 默认是True的\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg,param_grid,cv=5,scoring=\"neg_mean_squared_error\",return_train_score=True)\n",
    "# 你应该注意到了 几乎所有的模式都是先按照某些超参把这个模型建立起来，然后再让这个模型去fit数据\n",
    "grid_search.fit(housing_prepared,housing_labels)\n",
    "# 通过训练后可以通过grid_search的best_params_属性来得到找到的最佳超参\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab64ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可通过grid_search的best_estimator_来看最佳的预测器的超参设置\n",
    "grid_search.best_estimator_\n",
    "# 更多用法可见 https://www.cnblogs.com/dalege/p/14175192.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 但是需要指出网格搜索对于庞大的超参数空间是十分耗时的\n",
    "###### 所以此时可以选用 RandomSearchCV，通过设置迭代步数来对超参数的组合数进行限制而达到减小耗时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ec4db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06788579, 0.06172798, 0.04149555, 0.02542577, 0.0232485 ,\n",
       "       0.02460415, 0.02139649, 0.33203862, 0.06285406, 0.1058211 ,\n",
       "       0.07563495, 0.01942744, 0.11864258, 0.00047536, 0.00689856,\n",
       "       0.01242309])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 2. 另一种对模型进行微调的方法是将表现得很好的一些模型进行组合\n",
    "###### 进行如上操作首先需要分析表现得很好的模型\n",
    "# 查看表现得很好的模型的特征参数\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cate\"] # 现在当初起得名字就有作用了\n",
    "cat_one_hot_attr = list(cat_encoder.categories_[0]) # categories_中包含了所有类特征的所有值，由于只有一个类特征，所以只需要取第一个就可以了\n",
    "attrs = num_attr+extra_attribs+cat_one_hot_attr\n",
    "sorted(zip(feature_importances,attrs),reverse=True) # zip(a,b)将a,b这两个可迭代对象中的元素一个个打包成一个元组，返回一个元组的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51592b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "\n",
    "                                                # Evaluate Your System on the Test Set #\n",
    "    \n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "273f03dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54503.17006937851"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 经过上面的训练，我们找出了当前环境下表现最好的模型，然后我们就需要对这个模型在测试集上进行验证\n",
    "### 注意我们是在验证集上进行交叉验证选择了比较好的一些模型，然后对这些模型又进行了交叉验证来进行超参选择等的fine-tune后来到了这里\n",
    "# 首先还是需要将测试集的特征和标签分开，然后把特征transform一下\n",
    "X_test = strat_test_set.drop(\"median_house_value\",axis=1)\n",
    "Y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_transformed = full_pipeline.transform(X_test) # 注意这里不能使用 fit_transform 因为测试集上你绝对不能fit\n",
    "# 召唤出训练好的，调整好超参的模型\n",
    "final_model = grid_search.best_estimator_\n",
    "final_predictions = final_model.predict(X_test_transformed)\n",
    "final_rmse = np.sqrt(mean_squared_error(Y_test,final_predictions))\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7326358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53385.1304235 , 55598.73150432])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 如何判断这个预测的准确性呢？\n",
    "### 我们考虑预测均方误差的范围\n",
    "### 通过置信区间的来看看\n",
    "from scipy import stats\n",
    "confidence = 0.95 # 设置置信度\n",
    "squared_errors = (final_predictions-Y_test)**2\n",
    "np.sqrt(stats.t.interval(confidence,len(squared_errors)-1, loc=squared_errors.mean(),scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51304f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 也就是说预测的均方误差有95%的可能性落在长度为其十分之一区间中，误差取得的区间比较小，说明预测还是比较集中的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879903a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "\n",
    "                                            # Launch, Monitor, and Maintain Your System #\n",
    "    \n",
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb83073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "\n",
    "                                                       # Excercise #\n",
    "    \n",
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecafef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   0.5s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   0.4s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   0.4s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   0.4s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   0.4s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   0.4s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   0.5s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   0.5s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   0.5s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   0.5s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   0.4s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   0.5s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=   1.0s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=   1.2s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=   1.2s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=   1.0s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=   1.0s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=   0.9s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [10.0, 30.0, 100.0, 300.0],\n",
       "                          'kernel': ['linear']},\n",
       "                         {'C': [1.0, 3.0, 10.0, 30.0],\n",
       "                          'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0],\n",
       "                          'kernel': ['rbf']}],\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# housing_prepared 特征\n",
    "# housing_labels   标签\n",
    "### 1. \n",
    "## 设置该模型的超参数\n",
    "param_svm = [\n",
    "    {\"kernel\":['linear'],'C':[10.,30.,100.,300.]},\n",
    "    {\"kernel\":['rbf'],'C':[1.0,3.0,10.,30.],'gamma':[0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "]\n",
    "from sklearn.svm import SVR\n",
    "svm_model = SVR()\n",
    "grid_search = GridSearchCV(svm_model,param_svm,cv = 5,scoring=\"neg_mean_squared_error\",verbose=2)\n",
    "grid_search.fit(housing_prepared,housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83a4b30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 300.0, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rmse = np.sqrt(-grid_search.best_score_)\n",
    "svm_rmse\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a8876fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   0.5s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   0.5s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   0.4s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   0.4s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   0.5s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   1.1s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   0.4s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   0.4s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   0.4s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   0.4s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   0.4s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=   1.1s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   0.4s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   0.5s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   0.4s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   0.4s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   0.4s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=   2.2s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=   2.0s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=   2.2s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=   2.0s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=   2.4s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=   0.8s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=   1.2s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=   0.8s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=   0.8s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=   0.9s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=   2.3s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=   6.4s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=   3.8s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=   2.7s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=   3.5s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   0.5s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   1.0s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   0.5s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   0.5s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   0.5s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=   0.9s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=   1.2s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=   1.1s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=   1.0s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=   0.9s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   0.4s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   0.4s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   0.4s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   0.5s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   0.4s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=   1.2s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=   1.1s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=   1.1s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   0.4s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   0.4s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   0.5s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   0.5s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   0.4s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time=   3.1s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time=   2.6s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time=   3.3s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time=   2.9s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time=   3.0s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   0.4s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   0.4s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   0.4s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   0.4s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   0.4s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=   3.0s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=   2.7s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=   1.7s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=   1.8s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=   2.0s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   0.4s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   0.5s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   0.6s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   0.4s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   0.5s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   0.4s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   0.4s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   0.4s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   0.4s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   0.4s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   0.5s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   0.5s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   0.5s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   0.5s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   0.5s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   0.4s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   0.4s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   0.4s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   0.4s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   0.4s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   0.7s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   0.7s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   0.9s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   0.6s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   0.8s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=   2.2s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=   2.1s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=   2.1s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=   2.3s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=   2.1s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=   1.4s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=   1.7s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=   1.4s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=   1.4s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=   1.7s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   0.4s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   0.4s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   0.4s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   0.4s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   0.4s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   0.4s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   0.4s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   0.5s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   0.4s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   0.4s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   0.4s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   0.5s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   0.5s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   0.4s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   0.4s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   0.4s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   0.4s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   0.4s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   0.5s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   0.5s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   1.6s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   0.5s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   0.6s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   0.4s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   0.6s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   0.4s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   0.4s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   0.4s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   0.4s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   0.4s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   0.4s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   0.4s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   0.4s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   0.5s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   0.6s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   0.5s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   0.6s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   0.5s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=   1.6s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=   1.5s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=   1.5s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=   1.5s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=   1.5s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=   1.0s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=   0.8s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=   0.9s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=   1.0s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=   1.2s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=   0.9s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=   1.2s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=   0.9s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=   1.7s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=   2.2s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=   2.0s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=   2.1s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=   2.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVR(), n_iter=50,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001ED4F7B6B38>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001ED4F7B66D8>,\n",
       "                                        'kernel': ['linear', 'rbf']},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2. \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "param_distribs = {\n",
    "    'kernel':['linear','rbf'],\n",
    "    'C':reciprocal(20,200000),\n",
    "    'gamma':expon(scale=1.0)\n",
    "}\n",
    "radom_search = RandomizedSearchCV(svm_model,param_distributions=param_distribs,cv=5,n_iter=50,scoring=\"neg_mean_squared_error\",verbose=2,random_state=42)\n",
    "radom_search.fit(housing_prepared,housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31878116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 157055.10989448498, 'gamma': 0.26497040005002437, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rmse = np.sqrt(-radom_search.best_score_)\n",
    "svm_rmse\n",
    "radom_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03974af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# np.argpartition(arr,i),找到数组arr中第i-1小的数字，并将所有比该数字小的数放在它前面，比它大的数放在它后面\n",
    "# 如果是要找第i-1(写i)大的数字，本质上是找第n-i+1(写n-i)小的数字，这里写作-i,[-k:]表示从倒数第一个到倒数第k个\n",
    "def indices_of_top_k(arr,k):\n",
    "    return np.sort(np.argpartition(np.array(arr),-k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,feature_importances,k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self,X,y=None):\n",
    "        self.feature_indices = indices_of_top_k(self.feature_importances,self.k)\n",
    "        return\n",
    "    def transform(self,X):\n",
    "        return X[:,self.feature_indices] # 返回X的所有行这些列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47d08d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7,  9, 10, 12], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_of_top_k(feature_importances,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d708cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57507019,  2.35845461, -0.43699104, -0.88424924,  0.        ],\n",
       "       [-0.43480141,  0.61735909,  0.03395612, -0.96141918,  0.        ],\n",
       "       [ 0.54522177,  0.28422164, -0.01843971, -0.43826533,  0.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparation_and_feature_select = Pipeline([\n",
    "    ('preparation',full_pipeline),\n",
    "    ('feature_select',TopFeatureSelector(feature_importances,5))\n",
    "])\n",
    "preparation_and_feature_select.fit(housing)\n",
    "housing_preparation_top_k_features = preparation_and_feature_select.transform(housing)\n",
    "housing_preparation_top_k_features[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46f6b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparation',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('add_addr',\n",
       "                                                                   CombineAttributesAddr()),\n",
       "                                                                  ('std_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['longitude', 'latitude',\n",
       "                                                   'housing_median_age',\n",
       "                                                   'total_rooms',\n",
       "                                                   'total_bedrooms',\n",
       "                                                   'population', 'households',\n",
       "                                                   'median_income']),\n",
       "                                                 ('cate', OneHotEncoder(),\n",
       "                                                  ['ocean_proximity'])])),\n",
       "                ('feature_select',\n",
       "                 TopFeatureSelector(feature_importances=array([0.06788579, 0.06172798, 0.04149555, 0.02542577, 0.0232485 ,\n",
       "       0.02460415, 0.02139649, 0.33203862, 0.06285406, 0.1058211 ,\n",
       "       0.07563495, 0.01942744, 0.11864258, 0.00047536, 0.00689856,\n",
       "       0.01242309]),\n",
       "                                    k=5))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733825aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
